services:
  mcp:
    build: .
    container_name: mcp-file-classifier
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - OLLAMA_MODEL_PATH=/mnt/ollama_models
    volumes:
      - ./files_to_sort:/files
      - C:\Users\soare\.ollama:/mnt/ollama_models
    command:
      [
        "/bin/sh",
        "-c",
        "ollama serve & \
             echo 'Démarrage du serveur Ollama en arrière-plan...' ; \
             sleep 5 ; \
             ollama pull deepseek-v3.1:671b-cloud ; \
             echo 'Modèle DeepSeek téléchargé. Démarrage du serveur MCP...' ; \
             exec python server.py"
      ]
